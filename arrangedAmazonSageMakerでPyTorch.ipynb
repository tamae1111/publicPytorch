{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00e081bb",
   "metadata": {},
   "source": [
    "# このipynbファイルの用途\n",
    "\n",
    "## 対象者\n",
    "　sagemakerとpytorchを組み合わせて使ってみたいユーザー\n",
    "\n",
    "##  できること\n",
    "    - sagemakerAPIとpytorchの組み合わせによる簡易訓練、デプロイの流れを理解できる\n",
    "    - カスタマイズする箇所がわかりやすいのでカスタムモデルの構築にスムーズに移行できる\n",
    "\n",
    "## 関連ファイル\n",
    "    - feature_extract_cifar10.py\n",
    "\n",
    "## 検証日\n",
    "    - 2023-12-13\n",
    "\n",
    "## ディレクトリ構成\n",
    "    - [初心者向け]Amazon SageMakerでPyTorch.ipynb\n",
    "    - feature_extract_cifar10.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35e63a94-39b7-41b3-839d-83097cbf5683",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 必要モデルのinstall\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "### 補足: sagemaker_trainingライブラリは今回は使用しない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c031fb32-f81f-4431-abe1-453fe49baf52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "CPU times: user 1.18 s, sys: 105 ms, total: 1.29 s\n",
      "Wall time: 1.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## 環境変数の設定 \n",
    "\n",
    "import sagemaker\n",
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "bucket='mlearning-bucket'\n",
    "prefix = 'sagemaker/cnn-cifar10'\n",
    "# customize to your bucket where you have stored the data\n",
    "bucket_path = 'https://s3-{}.amazonaws.com/{}'.format(region,bucket)\n",
    "\n",
    "### 補足: mlearning-bucketの箇所は自分の使用するsagemaker用のバケット名を指定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80ec119e-a18d-45d9-bb2b-3f609fd9a978",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:12<00:00, 13549803.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
      "Files already downloaded and verified\n",
      "CPU times: user 2.8 s, sys: 602 ms, total: 3.4 s\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## データセットのtransform設定\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "train_data = datasets.CIFAR10(root='../data', train=True, download=True, transform=transform)\n",
    "test_data = datasets.CIFAR10(root='../data', train=False, download=True, transform=transform)\n",
    "\n",
    "### 補足: torchvisionのdatasetsからデータのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17a82ca5-12f6-4e68-8926-b92d0b2ec562",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input spec (in this case, just an S3 path): s3://mlearning-bucket/sagemaker/cnn-cifar10\n",
      "CPU times: user 5.43 s, sys: 3.7 s, total: 9.13 s\n",
      "Wall time: 7.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## s3へのデータのアップロード\n",
    "inputs = sagemaker_session.upload_data(path='../data', bucket=bucket, key_prefix=prefix)\n",
    "print('input spec (in this case, just an S3 path): {}'.format(inputs))\n",
    "\n",
    "### 補足: s3のsagemaker/cnn-cifar10ディレクトリにアップロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "717db3a0-140d-4038-94ab-1b436fc1c4db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "## sagemakerのpytorchモデルを用いた予測クラスの生成\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "hyper_param = {\n",
    "    'epochs':100,\n",
    "    'batch-size': 100,\n",
    "    'lr': 0.01,\n",
    "    'momentum': 0.9,\n",
    "}\n",
    "\n",
    "estimator = PyTorch(entry_point='feature_extract_cifar10.py',\n",
    "                            hyperparameters=hyper_param,\n",
    "                            role=role,\n",
    "                            framework_version='1.2.0',\n",
    "                            py_version='py3',\n",
    "                            train_instance_count=2,\n",
    "                            train_instance_type='ml.c5.xlarge')\n",
    "\n",
    "print(f'トレーニングに使用するコンテナイメージは {estimator.training_image_uri()} です')\n",
    "### 補足: sagemakerのライブラリのアップデートに伴い、以下二つのオプションの設定が必要となったので、設定。;framework_version='1.2.0', py_version='py3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae55de62-ed0a-494c-a512-f163484e9808",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-12-13-09-28-13-112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-13 09:28:14 Starting - Starting the training job......\n",
      "2023-12-13 09:29:14 Starting - Preparing the instances for training.........\n",
      "2023-12-13 09:30:42 Downloading - Downloading input data.....\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2023-12-13 09:31:24,485 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2023-12-13 09:31:24,488 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2023-12-13 09:31:24,497 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2023-12-13 09:31:24,498 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2023-12-13 09:31:24,668 sagemaker-containers INFO     Module feature_extract_cifar10 does not provide a setup.py. \u001b[0m\n",
      "\u001b[35mGenerating setup.py\u001b[0m\n",
      "\u001b[35m2023-12-13 09:31:24,669 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[35m2023-12-13 09:31:24,669 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[35m2023-12-13 09:31:24,669 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[35mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: feature-extract-cifar10\n",
      "  Building wheel for feature-extract-cifar10 (setup.py): started\n",
      "  Building wheel for feature-extract-cifar10 (setup.py): finished with status 'done'\n",
      "  Created wheel for feature-extract-cifar10: filename=feature_extract_cifar10-1.0.0-py2.py3-none-any.whl size=8595 sha256=5fd02c0a5c54eb655276e4063baad865a1007e8b2f565cb8fef94b37e64127dd\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vyalaig2/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[35mSuccessfully built feature-extract-cifar10\u001b[0m\n",
      "\u001b[35mInstalling collected packages: feature-extract-cifar10\u001b[0m\n",
      "\u001b[35mSuccessfully installed feature-extract-cifar10-1.0.0\u001b[0m\n",
      "\u001b[35mWARNING: You are using pip version 19.3; however, version 21.3.1 is available.\u001b[0m\n",
      "\u001b[35mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[35m2023-12-13 09:31:25,907 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[35m2023-12-13 09:31:25,917 sagemaker-containers INFO     Invoking user script\u001b[0m\n",
      "\u001b[35mTraining Env:\u001b[0m\n",
      "\u001b[35m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-2\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 100,\n",
      "        \"epochs\": 100,\n",
      "        \"lr\": 0.01,\n",
      "        \"momentum\": 0.9\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": false,\n",
      "    \"job_name\": \"pytorch-training-2023-12-13-09-28-13-112\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-1-958305726855/pytorch-training-2023-12-13-09-28-13-112/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"feature_extract_cifar10\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-2\",\n",
      "        \"current_instance_type\": \"ml.c5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-2\",\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"feature_extract_cifar10.py\"\u001b[0m\n",
      "\u001b[35m}\u001b[0m\n",
      "\u001b[35mEnvironment variables:\u001b[0m\n",
      "\u001b[35mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[35mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[35mSM_HPS={\"batch-size\":100,\"epochs\":100,\"lr\":0.01,\"momentum\":0.9}\u001b[0m\n",
      "\u001b[35mSM_USER_ENTRY_POINT=feature_extract_cifar10.py\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[35mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.c5.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[35mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[35mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[35mSM_CURRENT_HOST=algo-2\u001b[0m\n",
      "\u001b[35mSM_MODULE_NAME=feature_extract_cifar10\u001b[0m\n",
      "\u001b[35mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[35mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[35mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[35mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[35mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[35mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[35mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[35mSM_MODULE_DIR=s3://sagemaker-ap-northeast-1-958305726855/pytorch-training-2023-12-13-09-28-13-112/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[35mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-2\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch-size\":100,\"epochs\":100,\"lr\":0.01,\"momentum\":0.9},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":false,\"job_name\":\"pytorch-training-2023-12-13-09-28-13-112\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-1-958305726855/pytorch-training-2023-12-13-09-28-13-112/source/sourcedir.tar.gz\",\"module_name\":\"feature_extract_cifar10\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-2\",\"current_instance_type\":\"ml.c5.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"feature_extract_cifar10.py\"}\u001b[0m\n",
      "\u001b[35mSM_USER_ARGS=[\"--batch-size\",\"100\",\"--epochs\",\"100\",\"--lr\",\"0.01\",\"--momentum\",\"0.9\"]\u001b[0m\n",
      "\u001b[35mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[35mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[35mSM_HP_BATCH-SIZE=100\u001b[0m\n",
      "\u001b[35mSM_HP_EPOCHS=100\u001b[0m\n",
      "\u001b[35mSM_HP_LR=0.01\u001b[0m\n",
      "\u001b[35mSM_HP_MOMENTUM=0.9\u001b[0m\n",
      "\u001b[35mPYTHONPATH=/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[35mInvoking script with the following command:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python -m feature_extract_cifar10 --batch-size 100 --epochs 100 --lr 0.01 --momentum 0.9\u001b[0m\n",
      "\u001b[35mDownloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\u001b[0m\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-12-13 09:31:24,973 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-12-13 09:31:24,976 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-12-13 09:31:24,985 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-12-13 09:31:24,986 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-12-13 09:31:25,124 sagemaker-containers INFO     Module feature_extract_cifar10 does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2023-12-13 09:31:25,125 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2023-12-13 09:31:25,125 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2023-12-13 09:31:25,125 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: feature-extract-cifar10\n",
      "  Building wheel for feature-extract-cifar10 (setup.py): started\n",
      "  Building wheel for feature-extract-cifar10 (setup.py): finished with status 'done'\n",
      "  Created wheel for feature-extract-cifar10: filename=feature_extract_cifar10-1.0.0-py2.py3-none-any.whl size=8595 sha256=a0bb060a353d5d5c4d92aeeb9c8f0e626e621058c726211d9b6b86710b465333\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-sxxsfhxt/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built feature-extract-cifar10\u001b[0m\n",
      "\u001b[34mInstalling collected packages: feature-extract-cifar10\u001b[0m\n",
      "\u001b[34mSuccessfully installed feature-extract-cifar10-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 19.3; however, version 21.3.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2023-12-13 09:31:26,351 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-12-13 09:31:26,361 sagemaker-containers INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 100,\n",
      "        \"epochs\": 100,\n",
      "        \"lr\": 0.01,\n",
      "        \"momentum\": 0.9\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2023-12-13-09-28-13-112\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-ap-northeast-1-958305726855/pytorch-training-2023-12-13-09-28-13-112/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"feature_extract_cifar10\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.c5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.c5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-2\",\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"feature_extract_cifar10.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":100,\"epochs\":100,\"lr\":0.01,\"momentum\":0.9}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=feature_extract_cifar10.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=feature_extract_cifar10\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-ap-northeast-1-958305726855/pytorch-training-2023-12-13-09-28-13-112/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"batch-size\":100,\"epochs\":100,\"lr\":0.01,\"momentum\":0.9},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2023-12-13-09-28-13-112\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-ap-northeast-1-958305726855/pytorch-training-2023-12-13-09-28-13-112/source/sourcedir.tar.gz\",\"module_name\":\"feature_extract_cifar10\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.c5.xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.c5.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"feature_extract_cifar10.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"100\",\"--epochs\",\"100\",\"--lr\",\"0.01\",\"--momentum\",\"0.9\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=100\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=100\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.01\u001b[0m\n",
      "\u001b[34mSM_HP_MOMENTUM=0.9\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m feature_extract_cifar10 --batch-size 100 --epochs 100 --lr 0.01 --momentum 0.9\u001b[0m\n",
      "\u001b[34mDownloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\u001b[0m\n",
      "\n",
      "2023-12-13 09:31:22 Training - Training image download completed. Training in progress.\u001b[35mExtracting ../data/cifar-10-python.tar.gz to ../data\u001b[0m\n",
      "\u001b[34mExtracting ../data/cifar-10-python.tar.gz to ../data\u001b[0m\n",
      "\u001b[35mFiles already downloaded and verified\u001b[0m\n",
      "\u001b[35mProcesses 500/50000 (1%) of train data\u001b[0m\n",
      "\u001b[35mProcesses 100/10000 (1%) of test data\u001b[0m\n",
      "\u001b[34mFiles already downloaded and verified\u001b[0m\n",
      "\u001b[35mEpoch 0/99\u001b[0m\n",
      "\u001b[35m------------\u001b[0m\n",
      "\u001b[34mProcesses 500/50000 (1%) of train data\u001b[0m\n",
      "\u001b[34mProcesses 100/10000 (1%) of test data\u001b[0m\n",
      "\u001b[34mEpoch 0/99\u001b[0m\n",
      "\u001b[34m------------\u001b[0m\n",
      "\u001b[35mLoss: 1.932531 batch:  100 [ 10000/50000] Accuracy:  30.840%\u001b[0m\n",
      "\u001b[34mLoss: 1.932531 batch:  100 [ 10000/50000] Accuracy:  30.840%\u001b[0m\n",
      "\u001b[35mLoss: 1.838597 batch:  200 [ 20000/50000] Accuracy:  34.815%\u001b[0m\n",
      "\u001b[34mLoss: 1.838597 batch:  200 [ 20000/50000] Accuracy:  34.815%\u001b[0m\n",
      "\u001b[35mLoss: 1.791481 batch:  300 [ 30000/50000] Accuracy:  36.727%\u001b[0m\n",
      "\u001b[34mLoss: 1.791481 batch:  300 [ 30000/50000] Accuracy:  36.727%\u001b[0m\n",
      "\u001b[35mLoss: 1.758381 batch:  400 [ 40000/50000] Accuracy:  37.913%\u001b[0m\n",
      "\u001b[34mLoss: 1.758381 batch:  400 [ 40000/50000] Accuracy:  37.913%\u001b[0m\n",
      "\u001b[35mLoss: 1.738230 batch:  500 [ 50000/50000] Accuracy:  38.520%\u001b[0m\n",
      "\u001b[35mEpoch 1/99\u001b[0m\n",
      "\u001b[35m------------\u001b[0m\n",
      "\u001b[34mLoss: 1.738230 batch:  500 [ 50000/50000] Accuracy:  38.520%\u001b[0m\n",
      "\u001b[34mEpoch 1/99\u001b[0m\n",
      "\u001b[34m------------\u001b[0m\n",
      "\u001b[35mLoss: 1.589638 batch:  100 [ 10000/50000] Accuracy:  43.690%\u001b[0m\n",
      "\u001b[34mLoss: 1.589638 batch:  100 [ 10000/50000] Accuracy:  43.690%\u001b[0m\n",
      "\u001b[35mLoss: 1.585167 batch:  200 [ 20000/50000] Accuracy:  43.880%\u001b[0m\n",
      "\u001b[34mLoss: 1.585167 batch:  200 [ 20000/50000] Accuracy:  43.880%\u001b[0m\n",
      "\u001b[35mLoss: 1.580558 batch:  300 [ 30000/50000] Accuracy:  43.890%\u001b[0m\n",
      "\u001b[34mLoss: 1.580558 batch:  300 [ 30000/50000] Accuracy:  43.890%\u001b[0m\n",
      "\u001b[35mLoss: 1.578954 batch:  400 [ 40000/50000] Accuracy:  43.907%\u001b[0m\n",
      "\u001b[34mLoss: 1.578954 batch:  400 [ 40000/50000] Accuracy:  43.907%\u001b[0m\n",
      "\u001b[35mLoss: 1.578266 batch:  500 [ 50000/50000] Accuracy:  44.066%\u001b[0m\n",
      "\u001b[35mEpoch 2/99\u001b[0m\n",
      "\u001b[35m------------\u001b[0m\n",
      "\u001b[34mLoss: 1.578266 batch:  500 [ 50000/50000] Accuracy:  44.066%\u001b[0m\n",
      "\u001b[34mEpoch 2/99\u001b[0m\n",
      "\u001b[34m------------\u001b[0m\n",
      "\u001b[35mLoss: 1.511279 batch:  100 [ 10000/50000] Accuracy:  46.550%\u001b[0m\n",
      "\u001b[34mLoss: 1.511279 batch:  100 [ 10000/50000] Accuracy:  46.550%\u001b[0m\n",
      "\u001b[35mLoss: 1.518263 batch:  200 [ 20000/50000] Accuracy:  46.245%\u001b[0m\n",
      "\u001b[34mLoss: 1.518263 batch:  200 [ 20000/50000] Accuracy:  46.245%\u001b[0m\n",
      "\u001b[35mLoss: 1.526446 batch:  300 [ 30000/50000] Accuracy:  45.990%\u001b[0m\n",
      "\u001b[34mLoss: 1.526446 batch:  300 [ 30000/50000] Accuracy:  45.990%\u001b[0m\n",
      "\u001b[35mLoss: 1.525425 batch:  400 [ 40000/50000] Accuracy:  45.972%\u001b[0m\n",
      "\u001b[34mLoss: 1.525425 batch:  400 [ 40000/50000] Accuracy:  45.972%\u001b[0m\n",
      "\u001b[35mLoss: 1.522651 batch:  500 [ 50000/50000] Accuracy:  46.102%\u001b[0m\n",
      "\u001b[35mEpoch 3/99\u001b[0m\n",
      "\u001b[35m------------\u001b[0m\n",
      "\u001b[34mLoss: 1.522651 batch:  500 [ 50000/50000] Accuracy:  46.102%\u001b[0m\n",
      "\u001b[34mEpoch 3/99\u001b[0m\n",
      "\u001b[34m------------\u001b[0m\n",
      "\u001b[35mLoss: 1.481620 batch:  100 [ 10000/50000] Accuracy:  47.710%\u001b[0m\n",
      "\u001b[34mLoss: 1.481620 batch:  100 [ 10000/50000] Accuracy:  47.710%\u001b[0m\n",
      "\u001b[35mLoss: 1.492974 batch:  200 [ 20000/50000] Accuracy:  47.305%\u001b[0m\n",
      "\u001b[34mLoss: 1.492974 batch:  200 [ 20000/50000] Accuracy:  47.305%\u001b[0m\n",
      "\u001b[35mLoss: 1.488279 batch:  300 [ 30000/50000] Accuracy:  47.340%\u001b[0m\n",
      "\u001b[34mLoss: 1.488279 batch:  300 [ 30000/50000] Accuracy:  47.340%\u001b[0m\n",
      "\u001b[35mLoss: 1.489726 batch:  400 [ 40000/50000] Accuracy:  47.343%\u001b[0m\n",
      "\u001b[34mLoss: 1.489726 batch:  400 [ 40000/50000] Accuracy:  47.343%\u001b[0m\n",
      "\u001b[35mLoss: 1.492151 batch:  500 [ 50000/50000] Accuracy:  47.280%\u001b[0m\n",
      "\u001b[35mEpoch 4/99\u001b[0m\n",
      "\u001b[35m------------\u001b[0m\n",
      "\u001b[34mLoss: 1.492151 batch:  500 [ 50000/50000] Accuracy:  47.280%\u001b[0m\n",
      "\u001b[34mEpoch 4/99\u001b[0m\n",
      "\u001b[34m------------\u001b[0m\n",
      "\u001b[35mLoss: 1.453907 batch:  100 [ 10000/50000] Accuracy:  48.670%\u001b[0m\n",
      "\u001b[34mLoss: 1.453907 batch:  100 [ 10000/50000] Accuracy:  48.670%\u001b[0m\n",
      "\u001b[35mLoss: 1.447953 batch:  200 [ 20000/50000] Accuracy:  49.190%\u001b[0m\n",
      "\u001b[34mLoss: 1.447953 batch:  200 [ 20000/50000] Accuracy:  49.190%\u001b[0m\n",
      "\u001b[35mLoss: 1.451357 batch:  300 [ 30000/50000] Accuracy:  48.963%\u001b[0m\n",
      "\u001b[34mLoss: 1.451357 batch:  300 [ 30000/50000] Accuracy:  48.963%\u001b[0m\n",
      "\u001b[35mLoss: 1.455174 batch:  400 [ 40000/50000] Accuracy:  48.672%\u001b[0m\n",
      "\u001b[34mLoss: 1.455174 batch:  400 [ 40000/50000] Accuracy:  48.672%\u001b[0m\n",
      "\u001b[35mLoss: 1.454653 batch:  500 [ 50000/50000] Accuracy:  48.812%\u001b[0m\n",
      "\u001b[35mEpoch 5/99\u001b[0m\n",
      "\u001b[35m------------\u001b[0m\n",
      "\u001b[34mLoss: 1.454653 batch:  500 [ 50000/50000] Accuracy:  48.812%\u001b[0m\n",
      "\u001b[34mEpoch 5/99\u001b[0m\n",
      "\u001b[34m------------\u001b[0m\n",
      "\u001b[35mLoss: 1.428702 batch:  100 [ 10000/50000] Accuracy:  50.010%\u001b[0m\n",
      "\u001b[34mLoss: 1.428702 batch:  100 [ 10000/50000] Accuracy:  50.010%\u001b[0m\n",
      "\u001b[35mLoss: 1.428446 batch:  200 [ 20000/50000] Accuracy:  49.640%\u001b[0m\n",
      "\u001b[34mLoss: 1.428446 batch:  200 [ 20000/50000] Accuracy:  49.640%\u001b[0m\n",
      "\u001b[35mLoss: 1.428222 batch:  300 [ 30000/50000] Accuracy:  49.530%\u001b[0m\n",
      "\u001b[34mLoss: 1.428222 batch:  300 [ 30000/50000] Accuracy:  49.530%\u001b[0m\n",
      "\u001b[35mLoss: 1.432514 batch:  400 [ 40000/50000] Accuracy:  49.440%\u001b[0m\n",
      "\u001b[34mLoss: 1.432514 batch:  400 [ 40000/50000] Accuracy:  49.440%\u001b[0m\n",
      "\u001b[35mLoss: 1.431703 batch:  500 [ 50000/50000] Accuracy:  49.434%\u001b[0m\n",
      "\u001b[35mEpoch 6/99\u001b[0m\n",
      "\u001b[35m------------\u001b[0m\n",
      "\u001b[34mLoss: 1.431703 batch:  500 [ 50000/50000] Accuracy:  49.434%\u001b[0m\n",
      "\u001b[34mEpoch 6/99\u001b[0m\n",
      "\u001b[34m------------\u001b[0m\n",
      "\u001b[35mLoss: 1.381977 batch:  100 [ 10000/50000] Accuracy:  51.290%\u001b[0m\n",
      "\u001b[34mLoss: 1.381977 batch:  100 [ 10000/50000] Accuracy:  51.290%\u001b[0m\n",
      "\u001b[35mLoss: 1.388561 batch:  200 [ 20000/50000] Accuracy:  50.950%\u001b[0m\n",
      "\u001b[34mLoss: 1.388561 batch:  200 [ 20000/50000] Accuracy:  50.950%\u001b[0m\n",
      "\u001b[35mLoss: 1.395390 batch:  300 [ 30000/50000] Accuracy:  50.757%\u001b[0m\n",
      "\u001b[34mLoss: 1.395390 batch:  300 [ 30000/50000] Accuracy:  50.757%\u001b[0m\n",
      "\u001b[35mLoss: 1.398928 batch:  400 [ 40000/50000] Accuracy:  50.530%\u001b[0m\n",
      "\u001b[34mLoss: 1.398928 batch:  400 [ 40000/50000] Accuracy:  50.530%\u001b[0m\n",
      "\u001b[35mLoss: 1.396871 batch:  500 [ 50000/50000] Accuracy:  50.682%\u001b[0m\n",
      "\u001b[35mEpoch 7/99\u001b[0m\n",
      "\u001b[35m------------\u001b[0m\n",
      "\u001b[34mLoss: 1.396871 batch:  500 [ 50000/50000] Accuracy:  50.682%\u001b[0m\n",
      "\u001b[34mEpoch 7/99\u001b[0m\n",
      "\u001b[34m------------\u001b[0m\n",
      "\u001b[35mLoss: 1.382832 batch:  100 [ 10000/50000] Accuracy:  50.840%\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## 訓練の実行\n",
    "estimator.fit({'training': inputs}, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c70925f-a97d-4205-b2c6-ae0cee48b9f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## モデルのデプロイ\n",
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a30ad-3fe5-4c49-b9be-ab7844d64dec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## モデルの検証\n",
    "import numpy as np\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "\n",
    "## テストのための設定\n",
    "test_loader = DataLoader(test_data, batch_size=100, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = predictor.predict(images.numpy())\n",
    "        _, predicted = torch.max(torch.from_numpy(np.array(outputs)), 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))\n",
    "### 補足2：feature_extract_cifarの中身がs3のデータを使用する形になっていないので、s3の該当のデータをとってくるよう修正が必要\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4c4d2a-63f5-4fbd-85fd-b84932c75b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## モデルの後片付け\n",
    "endpointName = \"<<ここに上記で作り、返却されているsagemakerのendpoint名を記載>>\"\n",
    "\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "response = sagemaker_client.delete_endpoint(\n",
    "    EndpointName=endpointName\n",
    ")\n",
    "\n",
    "## 補足：boto3はawsのコンテナであればデフォルトでinstallされている可能性が高い"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
